{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with ReactorTwin\n",
    "\n",
    "**ReactorTwin** is a physics-constrained Neural Differential Equation library for building chemical reactor digital twins.\n",
    "\n",
    "In this notebook, we will cover the core workflow:\n",
    "\n",
    "1. **Setting up reactors** -- defining kinetics and reactor geometry\n",
    "2. **Simulating with scipy** -- generating ground-truth trajectories\n",
    "3. **Training Neural ODEs** -- learning dynamics from data\n",
    "4. **Applying physics constraints** -- enforcing physical laws\n",
    "5. **Using the built-in Trainer** -- convenient training with validation and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from reactor_twin import (\n",
    "    ArrheniusKinetics, CSTRReactor, BatchReactor,\n",
    "    NeuralODE, PositivityConstraint, Trainer, ReactorDataGenerator,\n",
    "    create_exothermic_cstr, create_van_de_vusse_cstr,\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating a CSTR Reactor\n",
    "\n",
    "A **Continuous Stirred-Tank Reactor (CSTR)** is a standard model in chemical engineering. It assumes\n",
    "perfect mixing inside the vessel so that the outlet composition equals the interior composition.\n",
    "\n",
    "We define **Arrhenius kinetics** for a simple first-order reaction A -> B, then wrap them in a\n",
    "`CSTRReactor` with volume, flow rate, and feed conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinetics = ArrheniusKinetics(\n",
    "    name=\"A_to_B\",\n",
    "    num_reactions=1,\n",
    "    params={\n",
    "        \"k0\": np.array([1e10]),\n",
    "        \"Ea\": np.array([50000.0]),\n",
    "        \"stoich\": np.array([[-1, 1]]),\n",
    "    },\n",
    ")\n",
    "\n",
    "reactor = CSTRReactor(\n",
    "    name=\"tutorial_cstr\",\n",
    "    num_species=2,\n",
    "    params={\n",
    "        \"V\": 100.0,    # Volume (L)\n",
    "        \"F\": 10.0,     # Flow rate (L/min)\n",
    "        \"C_feed\": [1.0, 0.0],  # Feed concentrations (mol/L)\n",
    "        \"T_feed\": 350.0,       # Feed temperature (K)\n",
    "    },\n",
    "    kinetics=kinetics,\n",
    "    isothermal=True,\n",
    ")\n",
    "\n",
    "print(f\"Reactor: {reactor}\")\n",
    "print(f\"State labels: {reactor.get_state_labels()}\")\n",
    "print(f\"Initial state: {reactor.get_initial_state()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simulating with scipy\n",
    "\n",
    "Every reactor exposes an `ode_rhs` method that returns dy/dt given the current state.\n",
    "We can plug this directly into `scipy.integrate.solve_ivp` to generate ground-truth trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = reactor.get_initial_state()\n",
    "t_span = np.linspace(0, 10, 100)\n",
    "\n",
    "sol = solve_ivp(\n",
    "    reactor.ode_rhs,\n",
    "    [t_span[0], t_span[-1]],\n",
    "    y0,\n",
    "    t_eval=t_span,\n",
    "    method=\"LSODA\",\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(sol.t, sol.y[0], 'b-', label='C_A')\n",
    "axes[0].plot(sol.t, sol.y[1], 'r-', label='C_B')\n",
    "axes[0].set_xlabel('Time (min)')\n",
    "axes[0].set_ylabel('Concentration (mol/L)')\n",
    "axes[0].set_title('CSTR: A -> B')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Also try the pre-built exothermic system\n",
    "reactor_exo = create_exothermic_cstr(isothermal=False)\n",
    "y0_exo = reactor_exo.get_initial_state()\n",
    "sol_exo = solve_ivp(reactor_exo.ode_rhs, [0, 5], y0_exo, t_eval=np.linspace(0, 5, 200), method=\"LSODA\")\n",
    "\n",
    "axes[1].plot(sol_exo.t, sol_exo.y[2], 'g-')\n",
    "axes[1].set_xlabel('Time (min)')\n",
    "axes[1].set_ylabel('Temperature (K)')\n",
    "axes[1].set_title('Non-isothermal CSTR Temperature')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training a Neural ODE\n",
    "\n",
    "**Neural ODEs** learn dynamics from data by parameterizing the right-hand side of an ODE with a\n",
    "neural network:\n",
    "\n",
    "$$\\frac{dy}{dt} = f_\\theta(t, y)$$\n",
    "\n",
    "The network $f_\\theta$ is trained to minimize the difference between predicted and observed\n",
    "trajectories. ReactorTwin provides a `NeuralODE` class that handles integration, loss computation,\n",
    "and adjoint sensitivity methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "z0 = torch.tensor(y0, dtype=torch.float32).unsqueeze(0)  # (1, state_dim)\n",
    "t_tensor = torch.tensor(t_span, dtype=torch.float32)\n",
    "targets = torch.tensor(sol.y.T, dtype=torch.float32).unsqueeze(0)  # (1, T, state_dim)\n",
    "\n",
    "# Create Neural ODE\n",
    "model = NeuralODE(\n",
    "    state_dim=2,\n",
    "    hidden_dim=64,\n",
    "    num_layers=3,\n",
    "    solver=\"rk4\",\n",
    "    adjoint=False,\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(300):\n",
    "    optimizer.zero_grad()\n",
    "    preds = model(z0, t_tensor)\n",
    "    loss_dict = model.compute_loss(preds, targets)\n",
    "    loss_dict[\"total\"].backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    losses.append(loss_dict[\"total\"].item())\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1:4d}: loss = {losses[-1]:.6f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.semilogy(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating Predictions\n",
    "\n",
    "Let's compare the Neural ODE predictions against the ground-truth scipy solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(z0, t_tensor)\n",
    "\n",
    "pred_np = preds[0].numpy()\n",
    "true_np = sol.y.T\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "for i, (name, color) in enumerate([('C_A', 'blue'), ('C_B', 'red')]):\n",
    "    axes[i].plot(t_span, true_np[:, i], f'{color[0]}--', label='Ground truth', linewidth=2)\n",
    "    axes[i].plot(t_span, pred_np[:, i], f'{color[0]}-', label='Neural ODE', linewidth=1.5)\n",
    "    axes[i].set_xlabel('Time (min)')\n",
    "    axes[i].set_ylabel(f'{name} (mol/L)')\n",
    "    axes[i].set_title(f'{name}: Prediction vs Truth')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mse = np.mean((pred_np - true_np) ** 2)\n",
    "print(f\"MSE: {mse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Applying Physics Constraints\n",
    "\n",
    "In chemical systems, concentrations must always be non-negative. The `PositivityConstraint`\n",
    "enforces this requirement either by **projecting** predictions (hard mode) or by adding a\n",
    "**penalty** to the loss (soft mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint = PositivityConstraint(mode=\"hard\", method=\"softplus\")\n",
    "constrained_preds, violation = constraint(preds)\n",
    "\n",
    "print(f\"Min (unconstrained): {preds.min().item():.6f}\")\n",
    "print(f\"Min (constrained):   {constrained_preds.min().item():.6f}\")\n",
    "print(f\"Violation:           {violation.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using the Trainer\n",
    "\n",
    "ReactorTwin ships with a built-in `Trainer` that handles the training loop, validation splits,\n",
    "learning rate scheduling, and checkpointing. Combined with `ReactorDataGenerator`, you can go\n",
    "from reactor definition to trained model in just a few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with the built-in data generator\n",
    "data_gen = ReactorDataGenerator(reactor=reactor)\n",
    "z0_batch, t_batch, targets_batch = data_gen.generate(\n",
    "    num_trajectories=5,\n",
    "    t_span=(0, 10),\n",
    "    num_points=50,\n",
    "    noise_std=0.01,\n",
    ")\n",
    "\n",
    "print(f\"Generated: z0={z0_batch.shape}, t={t_batch.shape}, targets={targets_batch.shape}\")\n",
    "\n",
    "# Use the Trainer\n",
    "trainer = Trainer(model=model, device=\"cpu\")\n",
    "history = trainer.train(\n",
    "    train_data=(z0_batch, t_batch, targets_batch),\n",
    "    num_epochs=50,\n",
    "    lr=5e-4,\n",
    "    verbose=False,\n",
    ")\n",
    "print(f\"Final training loss: {history['train_loss'][-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we covered the end-to-end ReactorTwin workflow:\n",
    "\n",
    "- **Reactor creation** -- `ArrheniusKinetics` + `CSTRReactor` (or the convenience constructors like `create_exothermic_cstr`)\n",
    "- **Simulation** -- plugging `ode_rhs` into scipy's `solve_ivp`\n",
    "- **Neural ODE training** -- learning dynamics from trajectory data\n",
    "- **Physics constraints** -- enforcing positivity with hard/soft modes\n",
    "- **Built-in Trainer** -- streamlined training with `Trainer` and `ReactorDataGenerator`\n",
    "\n",
    "Next, explore the full suite of physics constraints in **Notebook 02: Physics Constraints in ReactorTwin**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}